{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/terrierteam/pyterrier_doc2query.git\n",
    "!pip install python-terrier==0.9.2\n",
    "!pip install semanticscholar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorgehen\n",
    "\n",
    "## Allgemein\n",
    "\n",
    "TREC-Covid-Queries verwenden und erweitern um weitere Anfrageterme, um die Retrieval-Performance zu verbessern (Query Expansion). \n",
    "\n",
    "Für die QE müssen Termkandidaten (\"set of C\" c_1, c_2, c_3, ...) bestimmt werden, die anschließend gerankt werden.\n",
    "D.h. ihr sendet zunächst die Standard-Query ab und später nochmal für die finale Evaluierung, die Query mit Termerweiterungen.\n",
    "\n",
    "### LOKALE QE \n",
    "Word2Vec-Embeddings auf TREC-Covid trainieren (https://radimrehurek.com/gensim/)\n",
    "\n",
    "### GLOBALE QE\n",
    "Standardvariante wie z.B. auf Basis von Wikipedia.\n",
    "\n",
    "Wenn wenig Zeit:\n",
    "Nur die globale Variante evaluieren, wobei ja der \"Claim for Fame\" im Paper ist, dass die lokale Methode bessere Ergebnisse liefert."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard-Query an den Index für erstes Ranking\n",
    "Aus dem Title des Topics, quasi wie in der Standard-Pipeline in Pyterrier.\n",
    "Paper Inverse Document Frequency model (InL2)\n",
    "Zuerst BM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Erstellung der Termkandidaten\n",
    "## 2.1 Top-3 Dokumente\n",
    "Alle Terme (ausschließlich der Stoppworte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Terme der Referenzen\n",
    "Alle Terme aus den Referenzen der 3 Dokumente (Terme der Titel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Erweiterung mit Co-Autoren\n",
    "Über die Koautoren können noch weitere Dokumente bzw. die entsprechenden Terme hinzugefügt werden. Aus Zeitgründen könnte man vielleicht auch diesen Schritt weglassen, wenn es zu viel Aufwand ist über Koautoren weitere Dokumente zu finden. Bei der Implementierung scheint ihr ja aber schon recht weit zu sein. Die \"relevanten Paper der Autoren\" sind einfach die Top-k Dokumente oder möglicherweise alle zusätzlichen Papers, die über die Koautorenschaft gefunden werden, gemeint. Daher ergibt sich auf der Name PSEUDO-Relevanz-Feedback, da einfach angenommen wird, dass die Top-Treffer alle relevant sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.4 Ranking aller Terms\n",
    "Paper: Bo1\n",
    "Top-k Terme auswählen (k selbst wählen).\n",
    "Ergebnis: Potentielle Kandidaten für eine Termwerweiterung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Word2Vec-Modell mit Terms nachtrainieren\n",
    "Über die Kosinusähnlichkeit der Embeddings der ursprünglichen Anfrageterme bestimmt ihr nun weitere Terme aus dem Word2Vec-Modell. Diese Termkandidaten werden dann wie in 2.1.4 über Bo1 o.ä. gerankt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.6 Zwei Sets zusammenfügen und Top-k für QE der ursprünglichen Querry nutzen\n",
    "Diese jeweils für die 50 Topics absenden.\n",
    "\n",
    "Ergebnis: Die finalen Rankings, die dann ausgewertet werden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ae50ba892a007039ee8b8cd0574fd987a1c048ef5b59b149546a5ae9fb6dc134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
